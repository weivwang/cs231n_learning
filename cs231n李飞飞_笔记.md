2021-2-1

课程链接： https://www.bilibili.com/video/BV1nJ411z7fe?p=2&spm_id_from=pageDriver

课程重点：convolutional neural network (CNN) 卷积神经网络

<b>focus on</b>：

+ image classification problems. 图像分类问题

  ImageNet大赛推动了图像识别的发展，最近几年GPU性能提高较快，所以才允许该领域快速发展，另一个方面：数据量

  机器深刻地理解图像还早

<a href = "https://cs231n.github.io/python-numpy-tutorial/">python ，jupyter notebook tutorial</a>

对计算机来说，图片就是一个像素值矩阵

challenges：光线，形变，遮挡Occlusion，背景，类内差异(cats' color....)

Data-Driven Approach：从网上找一堆猫的照片，作为训练



简易模型：

train: 

​	def train(images, labels): 

​			return models

Predict: 

​	def predict(model, test_images):

​		return test_labels

---

<b>Lecture1</b>

<b>最近临近算法</b>：

L1 :曼哈顿距离

![IMG_0116](https://i.loli.net/2021/02/10/cA5pjUNB7VExJmk.png)

给出了一个比较两个图片相像性的方法。

落后的方法：train:O(1)

Predict: O(n)，n个比较



<b>K-最临近算法</b>：KNN

找到最近的k个点，更复杂，k越大，结果越好

L2 = L1取根号 ， 欧式距离 

L1基于我们对坐标轴的选择，L2不会



---

K的选择，距离的算法选择：超参数，不能从数据集里面获得，依赖于具体问题

比如选L1还是L2，依赖你到底要不要注重坐标轴的选择，best answer：depend on question

----

<b>Lecture2.  线性分类</b>

图片像素值 x----------f(x,W)------------参数-------------分类

W为权重（自己提出的） f(x,W) = Wx +b

![](https://i.loli.net/2021/02/10/qOUWS4Z6dRLhQ8X.png)

---



<b>Lecture3.  如何选择：W和 f(x, W)的形式？</b>

![IMG_0118](https://i.loli.net/2021/02/10/qOUWS4Z6dRLhQ8X.png)

回顾：

猫的图片------2\*2矩阵------4\*1矩阵------输入到f(x,W)

W为自己探索的得出的3\*4矩阵，f(x,W)为自己提出的函数，b为修正

在这里f(x,W) = Wx + b 可以得到一个3\*1的矩阵，对应3类，某一类的得分越高，则为该类的概率越高



<b>如何选择W？</b>

​	如果想让机器来进行评估，需要一个函数把W当输入，告诉我们这个W好不好，这个函数称作

**损失函数（loss function)**，可以定量地衡量W的好坏

---

**SVM loss** 

Support Vector Machine 支持向量机

Sj是通过分类器，预测出来的类的分数，S-Yi是这个样本的正确的分类标签



![IMG_0120](https://i.loli.net/2021/02/10/d5FcEvqJR8Hu1Ta.png)

最小值为0，最大值无穷

---

问题：发现一个W使L = 0，W唯一吗？

不唯一

---

通常在L（w）后面+一个lanmudaR(W)，正则项，防止过度拟合

---

**Softmax Classifier**

more common![IMG_0121](https://i.loli.net/2021/02/10/SnOb2cl5GvFAWZf.png)

最小值：0，最大化：inf

L_i = 0 代表真实，可以理解为损失程度，L_i越大，代表损失越多

![IMG_0122](https://i.loli.net/2021/02/10/6GPJAsUjwrivpB3.png)

---

**W最开始如何选？**

1，最笨办法：random

2，梯度：通常是选一个之后进行优化，往往用到梯度，告诉我们向那个方向移动一个步长，损失变化会是多少

在每一个维度修改一小部分，进行**有限差分逼近**

问题：W维度可能很多，或者CNN很大，导致计算很慢

可以用来debug

---

怎么计算梯度？ ：**反向传播算法**

就是求导的链式法则

---

之前讲的是线性分类

现在讲2层神经网络

W2对W1得到的分数h再进行一个加权![IMG_0126](https://i.loli.net/2021/02/10/5z7gcIdpyktDiEK.png)

![IMG_0127](https://i.loli.net/2021/02/10/juAqi4M5JadpNzm.png)



---

**卷积神经网络**

历史：

2012年神经网络爆发，最早是声音识别

CNN在ImageNet取得很好的效果，之后被广泛使用

人脸识别，姿势识别，alphago，医学图像识别

---

卷积核：用一个更小的矩阵滑过原矩阵

